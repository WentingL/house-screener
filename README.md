<!--
*** Thanks for checking out this README. If you have a suggestion
*** that would make this better, please fork the repo and create a pull request
*** or simply open an issue with the tag "enhancement".
*** Thanks again! Now go create something AMAZING! :D
-->

<!-- TABLE OF CONTENTS -->
<details open="open">
  <h3>Table of Contents</h3>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
      <ul>
        <li><a href="#built-with">Built With</a></li>
      </ul>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">Installation</a></li>
      </ul>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li>
      <a href="#roadmap">Roadmap</a>
      <ul>
        <li><a href="#uncertainty">Uncertainty</a></li>
      </ul>
    </li>
    <li><a href="#contributing">Contributing</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
    <li><a href="#acknowledgements">Acknowledgements</a></li>
  </ol>
</details>

<!-- ABOUT THE PROJECT -->
## About The Project
Web scraper - A tool that extracts information from webpages and
transform the raw data into structured and usable data for future
analysis.

<!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->

### Built With
- Python

<!-- GETTING STARTED -->
## Getting Started

<!--
This is an example of how you may give instructions on setting up your project locally.
To get a local copy up and running follow these simple example steps.
-->

### Prerequisites
<!-- This is an example of how to list things you need to use the
software and how to install them.

* npm
  ```sh
  npm install npm@latest -g
  ```
-->

### Installation
<!--
1. Get a free API Key at [https://example.com](https://example.com)
2. Clone the repo
   ```sh
   git clone https://github.com/your_username_/Project-Name.git
   ```
3. Install NPM packages
   ```sh
   npm install
   ```
   -->

<!-- USAGE EXAMPLES -->
## Usage

<!-- ROADMAP -->
## Roadmap
1. Start browser
    * Open a specific browser and load the url inputed from user
2. Automate element selector
    * Upen user selection, automatically determine the best element selectors
3. Output data
    * Export into nicely formatted csv files
Potential features:
- nice user interface

### Uncertainty <a name="uncertainty"/>
- Should the scraper be a browser add-on or an independent app?

<!-- CONTRIBUTING -->
## Contributing

Contributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are **greatly appreciated**.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

<!-- CONTACT -->
## Contact

Wenting Luo - kimluo2993@gmail.com

Project Link: [https://github.com/WentingL/web-scraper](https://github.com/WentingL/web-scraper)
